{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reads the heart rate data from your s1_laps_summary.csv file to understand the user's current heart rate during their running session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the datasets\n",
    "laps_summary_df = pd.read_csv('/mnt/data/s1_laps_summary.csv')\n",
    "spotify_songs_df = pd.read_csv('/mnt/data/spotify_songs.csv')\n",
    "\n",
    "# Display the first few rows of each dataset to understand their structure\n",
    "laps_summary_head = laps_summary_df.head()\n",
    "spotify_songs_head = spotify_songs_df.head()\n",
    "\n",
    "laps_summary_head, spotify_songs_head\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Laps Summary Dataset event_id, timestamp, heart_rate, time_elapsed, total_running_time, altitude, distance, speed, cadence, start_time, among other attributes related to running sessions. This dataset seems to track various metrics during running sessions, including the heart rate at different timestamps, which is crucial for your recommendation system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Spotify Songs Dataset Contains information about songs, including track_name, track_artist, track_popularity, track_album_id, track_album_name, track_album_release_date, playlist_name, playlist_id, playlist_genre, playlist_subgenre, danceability, energy, key, loudness, mode, speechiness, acousticness, instrumentalness, liveness, valence, tempo, duration_ms. The tempo field, representing the BPM of a song, will be particularly useful for matching songs to the runner's heart rate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Given this information, a valuable contribution could be to develop a script that:\n",
    "###### Calculates the average heart rate from the laps summary dataset.\n",
    "###### Selects songs from the Spotify dataset with tempos matching the calculated average heart rate.\n",
    "###### Generates a playlist of recommended songs based on the matching criteria."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generates a playlist of recommended songs based on the matching criteria. I will now proceed to create a simple version of such a script. This script will:\n",
    "\n",
    "#### Calculate the average heart rate of a given session.\n",
    "#### Find songs with tempos close to this average heart rate.\n",
    "#### Return a list of recommended songs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the average heart rate from the laps summary dataset\n",
    "average_heart_rate = laps_summary_df['heart_rate'].mean()\n",
    "\n",
    "# Now, let's find songs with tempos close to the average heart rate.\n",
    "# We will consider songs within a range of -10 and +10 BPM of the average heart rate.\n",
    "\n",
    "lower_tempo_limit = average_heart_rate - 10\n",
    "upper_tempo_limit = average_heart_rate + 10\n",
    "\n",
    "# Filter the Spotify songs dataset for songs within the tempo range\n",
    "matching_songs_df = spotify_songs_df[(spotify_songs_df['tempo'] >= lower_tempo_limit) & (spotify_songs_df['tempo'] <= upper_tempo_limit)]\n",
    "\n",
    "# Select a sample of matching songs to recommend\n",
    "recommended_songs_sample = matching_songs_df.sample(n=5, random_state=1) if not matching_songs_df.empty else \"No matching songs found\"\n",
    "\n",
    "average_heart_rate, recommended_songs_sample[['track_name', 'track_artist', 'tempo']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This was a very simple modeling not using an AI model or even any eda just to see how i should go around this project  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now I will do a simple eda to be able to impliment an ai model to check for recommendationds and calculate precision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For a basic Exploratory Data Analysis (EDA), we'll look into both datasets you've provided: the laps summary data and the Spotify songs data. The goal is to understand the distributions, identify patterns or anomalies, and glean insights that could inform the development of your recommendation system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Overview - Quick summary statistics and structure\n",
    "\n",
    "# Laps Summary Dataset Overview\n",
    "laps_summary_description = laps_summary_df.describe()\n",
    "laps_summary_info = laps_summary_df.info()\n",
    "\n",
    "# Spotify Songs Dataset Overview\n",
    "spotify_songs_description = spotify_songs_df.describe()\n",
    "spotify_songs_info = spotify_songs_df.info()\n",
    "\n",
    "# Display the descriptions for numerical columns\n",
    "laps_summary_description, spotify_songs_description\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values and impute with the mean\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Creating an imputer object to fill missing values with the mean of the column\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "\n",
    "# Applying the imputer to the heart_rate column of the laps summary dataset\n",
    "laps_summary_df['heart_rate_imputed'] = imputer.fit_transform(laps_summary_df[['heart_rate']])\n",
    "\n",
    "# Check if there are any missing values left in the heart_rate_imputed column\n",
    "missing_after_imputation = laps_summary_df['heart_rate_imputed'].isnull().sum()\n",
    "\n",
    "# Display the result\n",
    "missing_after_imputation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Takeaways for Recommendation System: Match Range: There's a good overlap between the heart rate range and the tempo range of songs, indicating potential for effective matching.\n",
    "### Variability Consideration: The variability in both heart rates and song tempos suggests the need for a recommendation system that can adapt to a wide range of user activities and musical preferences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set the style of seaborn\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "# Plot distributions\n",
    "fig, ax = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Distribution of Heart Rates\n",
    "sns.histplot(laps_summary_df['heart_rate'], bins=30, kde=True, ax=ax[0])\n",
    "ax[0].set_title('Distribution of Heart Rates')\n",
    "ax[0].set_xlabel('Heart Rate (BPM)')\n",
    "ax[0].set_ylabel('Frequency')\n",
    "\n",
    "# Distribution of Song Tempos\n",
    "sns.histplot(spotify_songs_df['tempo'], bins=30, kde=True, ax=ax[1])\n",
    "ax[1].set_title('Distribution of Song Tempos')\n",
    "ax[1].set_xlabel('Tempo (BPM)')\n",
    "ax[1].set_ylabel('Frequency')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I want to classify the day in low tempo or high tempo to further split the data and help the model understand and better our accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Reloading Spotify dataset\n",
    "spotify_songs_df = pd.read_csv('/mnt/data/spotify_songs.csv')\n",
    "\n",
    "# Prepare the Data: Label songs based on median tempo\n",
    "median_tempo = spotify_songs_df['tempo'].median()\n",
    "spotify_songs_df['tempo_high_low'] = (spotify_songs_df['tempo'] > median_tempo).astype(int)  # 1 for High, 0 for Low\n",
    "\n",
    "# Feature Selection: Using 'tempo' as the feature for simplicity\n",
    "X = spotify_songs_df[['tempo']]\n",
    "y = spotify_songs_df['tempo_high_low']\n",
    "\n",
    "# Splitting the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Data normalization\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Train the Model: Logistic Regression\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Evaluate the Model: Calculate accuracy on the test set\n",
    "predictions = model.predict(X_test_scaled)\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "\n",
    "accuracy\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f6d162b57a5f6304fa3113465907e8ac54436c48c2463b79fe390fa48d88103b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
